ZT-IX Brainstorming Progress
Date: 2026-02-10

What I looked up
1. PeeringDB OAuth/OIDC docs:
   - https://docs.peeringdb.com/howto/oauth/
   - https://auth.peeringdb.com/register/
2. ZeroTier API/auth docs:
   - https://docs.zerotier.com/api/
   - https://docs.zerotier.com/api-central/
   - https://docs.zerotier.com/api-tokens/
   - https://docs.zerotier.com/sso/

Key findings that affect architecture
1. PeeringDB supports OpenID Connect login and documented OAuth2/OIDC app registration.
2. PeeringDB access tokens can call PeeringDB APIs with `Authorization: Bearer <access_token>`.
3. PeeringDB user permission introspection is available from:
   - `https://auth.peeringdb.com/oauth2/userinfo?scope=peeringdb.manage%20peeringdb.read`
4. ZeroTier Central API is token-based (bearer API token), not a third-party OAuth login provider for this use case.
5. ZeroTier docs also include OIDC SSO, but that is for ZeroTier service/device SSO, not app-to-Central API auth.

How I would build this app
1. Backend first (FastAPI + PostgreSQL)
   - Implement PeeringDB OIDC Authorization Code flow with PKCE.
   - Persist sessions and map PeeringDB user ID to local user record.
   - Exchange code for tokens server-side and store access token encrypted at rest.
2. Identity and policy layer
   - Query PeeringDB API for ASN/network objects allowed for the user.
   - Use PeeringDB userinfo/permissions scope checks for authorization gates.
   - Enforce allowlist rules (for example, accepted ASN ranges or explicit ASN whitelist).
3. ZeroTier orchestration layer
   - Use a service-owned ZeroTier Central API token (stored as secret).
   - For each approved ASN/user request:
     - create or update member authorization in target ZeroTier network,
     - assign managed IP if needed,
     - write provisioning status/audit events.
4. UX flow
   - Login with PeeringDB -> choose ASN -> submit join request -> admin approval (or policy auto-approval) -> show active member state.
   - Add clear status states: `pending`, `approved`, `provisioning`, `active`, `failed`.
5. Operational safety
   - Idempotent provisioning jobs.
   - Retry with exponential backoff for ZeroTier API errors.
   - Full audit log for all auth, approvals, and provisioning changes.

Initial milestone breakdown
1. Milestone 1: Auth and onboarding
   - OIDC login, callback, session handling, ASN fetch.
2. Milestone 2: Membership workflow
   - Join request model, admin approve/reject, status tracking.
3. Milestone 3: ZeroTier provisioning
   - Central API client, member authorization, reconciliation task.
4. Milestone 4: Hardening
   - Tests, observability, rate limits, CSRF/session security.

Open decisions before implementation
1. Should approvals be fully automatic for verified ASN ownership or always admin-gated?
2. Is one shared ZeroTier network sufficient, or does each ASN get isolated network segments?
3. What exact PeeringDB scopes should be considered minimum for production?

---

Update: 2026-02-10

Decision
1. ZeroTier provisioning will use a provider abstraction with two supported modes:
   - `central` (ZeroTier Central API)
   - `self_hosted_controller` (self-hosted ZeroTier controller API via local service auth)
2. Scope remains control-plane independence only; automated roots/planet management is out of scope for phase 1.

Completed
1. Updated planning docs to remove Central-only assumptions and define provider-based provisioning:
   - `PRD.md`
   - `APP_FLOW.md`
   - `TECH_STACK.md`
   - `BACKEND_STRUCTURE.md`
   - `IMPLEMENTATION_PLAN.md`

In progress
1. No implementation code yet. Documentation alignment is complete.

Next
1. Implement Phase 5 Step 5.1 through Step 5.4:
   - provider interface
   - `central` adapter
   - `self_hosted_controller` adapter
   - Celery task provider selection from `ZT_PROVIDER`
2. Add provider contract tests and adapter selection tests.
3. Update `.env.example` for provider mode and credentials.

Known risks / notes
1. Self-hosted controller endpoint/auth behavior must be validated in integration tests before production rollout.
2. Provider API differences can cause behavior drift without strict contract tests.

---

Update: 2026-02-10 (Phase 1 bootstrap complete)

Completed
1. Implemented Phase 1 Step 1.1 project structure bootstrap:
   - Added `app/`, `tests/`, and `alembic/` scaffolding.
   - Added runnable FastAPI app entrypoint with health endpoint.
2. Implemented Phase 1 Step 1.2 pinned dependency setup:
   - Updated `pyproject.toml` with exact runtime and dev versions from `TECH_STACK.md`.
   - Synced environment with `uv sync --dev` and generated `uv.lock`.
3. Implemented Phase 1 Step 1.3 quality tooling configuration:
   - Added `ruff`, `mypy`, and `pytest` configuration in `pyproject.toml`.
   - Added baseline API health test.
4. Implemented Phase 1 Step 1.4 environment bootstrap:
   - Added `.env.example` with required secrets, endpoint settings, and provider mode variables.
5. Added missing `lessons.md` stub as required by `AGENTS.md`.
6. Updated bootstrap run instructions in `README.md`.

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest -q` passed.

In progress
1. No active implementation tasks.

Next
1. Start Phase 2 Step 2.1: SQLAlchemy model layer per `BACKEND_STRUCTURE.md`.
2. Start Phase 2 Step 2.2: Alembic initial migration from modeled schema.
3. Add Phase 2 database invariant tests (unique active request constraint and status transition rules).

Known bugs / regressions
1. None identified in Phase 1 bootstrap scope.

Notes
1. `uv run` and `uv sync` required elevated permissions in this environment due cache directory restrictions.

---

Update: 2026-02-10 (Local dependency profile decision documented)

Decision
1. Selected for local development dependencies:
   - Docker Compose for PostgreSQL and Redis only.
   - API/worker/test processes run directly with `uv run`.

Completed
1. Documented the selected local dependency profile in:
   - `TECH_STACK.md`
   - `IMPLEMENTATION_PLAN.md`
   - `README.md`

In progress
1. No implementation code changes in this update.

Next
1. Start Phase 2 Step 2.1: SQLAlchemy model layer per `BACKEND_STRUCTURE.md`.
2. Start Phase 2 Step 2.2: Alembic initial migration from modeled schema.
3. Add Phase 2 database invariant tests (unique active request constraint and status transition rules).

Known bugs / regressions
1. None identified for this documentation-only update.

---

Update: 2026-02-10 (Phase 2 data and migration foundation complete)

Completed
1. Implemented Phase 2 Step 2.1 SQLAlchemy data model layer per `BACKEND_STRUCTURE.md`:
   - Added DB base/metadata conventions and status enums.
   - Added ORM models for `app_user`, `user_asn`, `zt_network`, `join_request`, `zt_membership`, `oauth_state_nonce`, and `audit_event`.
   - Added DB session helpers.
2. Implemented Phase 2 Step 2.2 initial Alembic migration:
   - Wired Alembic to SQLAlchemy metadata.
   - Added initial revision creating enum, tables, indexes, and active-request partial unique index.
3. Implemented Phase 2 Step 2.3 repository layer:
   - Added repositories for users, user ASN mappings, join requests, memberships, and audit events.
   - Added repository error types for duplicate active request and invalid state transition.
4. Implemented Phase 2 Step 2.4 DB invariant tests:
   - Added DB fixtures and tests covering:
     - one active request per (`asn`, `zt_network_id`)
     - allowed/forbidden request status transitions

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest tests/db -q` passed.
4. `uv run pytest -q` passed.
5. Migration lifecycle verified with `uv run env DATABASE_URL=sqlite:////tmp/zt_ix_phase2.db alembic upgrade/downgrade/upgrade`.

In progress
1. No active implementation tasks.

Next
1. Start Phase 3 Step 3.1: `/auth/login` state/nonce/PKCE generation.
2. Start Phase 3 Step 3.2: `/auth/callback` state validation and token exchange path.
3. Add auth integration tests for success/failure callback branches.

Known bugs / regressions
1. `alembic upgrade head` against local PostgreSQL could not be validated in this session because PostgreSQL on `localhost:5432` was unavailable.

---

Update: 2026-02-10 (Phase 2 PostgreSQL verification gap closed)

Completed
1. Added concrete local dependency orchestration for documented infrastructure profile:
   - Added `docker-compose.yml` with pinned images for PostgreSQL `16.6` and Redis `7.4.1`.
   - Set PostgreSQL host mapping default to `5433` (`${POSTGRES_HOST_PORT:-5433}:5432`) to avoid local `5432` conflicts.
2. Aligned local default DB connection settings to host port `5433`:
   - `.env.example`
   - `app/db/session.py`
   - `alembic.ini`
3. Added README run instructions for starting local dependencies and documented the `5433` host-port expectation.
4. Fixed a PostgreSQL migration defect in `alembic/versions/20260210_0001_phase2_data_foundation.py`:
   - Removed redundant explicit enum creation causing duplicate `request_status` type creation during `upgrade`.
5. Completed previously blocked PostgreSQL migration verification using alternate host port override in this environment:
   - Ran upgrade/downgrade/upgrade successfully against running local PostgreSQL.

Verification
1. `docker compose ps` (PostgreSQL and Redis healthy).
2. `uv run env DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:55433/zt_ix alembic upgrade head && uv run env DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:55433/zt_ix alembic downgrade base && uv run env DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:55433/zt_ix alembic upgrade head` passed.
3. `uv run ruff check .` passed.
4. `uv run mypy .` passed.
5. `uv run pytest tests/db -q` passed.
6. `uv run pytest -q` passed.

In progress
1. No active implementation tasks.

Next
1. Start Phase 3 Step 3.1: `/auth/login` state/nonce/PKCE generation.
2. Start Phase 3 Step 3.2: `/auth/callback` state validation and token exchange path.
3. Add auth integration tests for success/failure callback branches.

Known bugs / regressions
1. None identified in Phase 2 scope after PostgreSQL verification.

Notes
1. In this environment, host port `5433` was already allocated; verification used `POSTGRES_HOST_PORT=55433` while keeping repo defaults at `5433`.
2. Added an AGENTS.md non-negotiable to keep escalation-sensitive commands on consistent prefixes (for example, `docker compose`, `uv run`) to reduce repeated approvals.

---

Update: 2026-02-10 (Implementation plan updated for route-server Option A + Option B TODO)

Decision
1. Route-server automation is now planned as Option A in active scope:
   - Worker-driven SSH orchestration to remote Ubuntu/Linux route servers.
   - Explicit generated BIRD peer configuration per ASN on every configured route server.
   - ROA/RPKI validation required in the BIRD policy/configuration path for generated peers.
2. Option B (persisted per-route-server state model) is deferred and tracked as a TODO phase after Phase 8.

Completed
1. Updated `IMPLEMENTATION_PLAN.md` to Version 0.3:
   - Added Option A assumptions/requirements.
   - Expanded Phase 5 steps and exit criteria for route-server sync via SSH.
   - Added explicit per-ASN peer generation requirement.
   - Added ROA/RPKI validation requirement.
   - Added post-Phase-8 TODO section for Option B.

In progress
1. No implementation code changes in this update.

Next
1. Align `PRD.md`, `APP_FLOW.md`, and `BACKEND_STRUCTURE.md` with the new route-server Option A scope before implementation begins.

---

Update: 2026-02-10 (Phase 4 request workflow complete)

Completed
1. Implemented Phase 4 Step 4.1 request APIs with ownership and duplicate protections:
   - Added `POST /api/v1/requests`, `GET /api/v1/requests`, `GET /api/v1/requests/{request_id}`.
   - Enforced ASN ownership via `user_asn` mappings and deterministic duplicate conflict responses.
   - Added target-network validation for active `zt_network` IDs before request creation.
2. Implemented Phase 4 Step 4.2 operator workflow pages:
   - Added `/dashboard` and `/requests/{request_id}` routes.
   - Expanded `/onboarding` payload to include eligible ASNs and active ZeroTier networks.
3. Implemented Phase 4 Step 4.3 admin queue/detail and decision APIs:
   - Added `/admin/requests` and `/admin/requests/{request_id}`.
   - Added `POST /api/v1/admin/requests/{request_id}/approve`.
   - Added `POST /api/v1/admin/requests/{request_id}/reject` with reject-reason validation.
   - Added `POST /api/v1/admin/requests/{request_id}/retry` with strict `failed -> approved` guard.
   - Added role-based session guards for operator/admin access checks.
4. Implemented Phase 4 Step 4.4 audit emission for workflow transitions:
   - Added `request.created` and `request.status.changed` audit writes with actor/status metadata.
5. Implemented Phase 4 Step 4.5 workflow integration tests:
   - Added `tests/workflow/test_request_workflow_integration.py`.
   - Added workflow test fixtures in `tests/workflow/conftest.py`.
   - Covered create/duplicate/ownership errors, operator visibility guards, admin approve/reject/retry transitions, and admin authorization failures.
6. Added supporting repository and session updates:
   - Added `app/repositories/zt_networks.py`.
   - Added admin queue filters in `JoinRequestRepository.list_for_admin`.
   - Updated user upsert behavior to preserve existing admin flags during OAuth login.

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest tests/workflow -q` passed.
4. `uv run pytest -q` passed.

In progress
1. No active implementation tasks.

Next
1. Start Phase 5 Step 5.1-5.4 provider abstraction/adapters and worker provider selection.
2. Replace Phase 4 provisioning enqueue placeholder with actual Celery task dispatch in Phase 5.
3. Add provisioning contract tests under `tests/provisioning`.

Known bugs / regressions
1. None identified in current Phase 4 scope.

Notes
1. Integration coverage added for Phase 4 API/page workflow paths using in-memory SQLite + OAuth stubbed login flow.
2. Define environment/config contract for route-server SSH fanout (inventory, auth, command policy).
3. Start Phase 3 auth implementation once scope docs are aligned.

Known bugs / regressions
1. None identified for this documentation-only update.

---

Update: 2026-02-10 (Phase 3 auth integration complete in code + automated tests)

Completed
1. Implemented Phase 3 Step 3.1 `/auth/login`:
   - Added OAuth state/nonce/PKCE generation and persistence (`oauth_state_nonce`).
   - Added redirect construction to PeeringDB authorize endpoint with PKCE challenge and nonce.
2. Implemented Phase 3 Step 3.2 `/auth/callback`:
   - Added one-time state consumption and expiry handling.
   - Added token exchange path and nonce validation via `id_token` nonce claim.
   - Added explicit callback failure codes and audit events.
3. Implemented Phase 3 Step 3.3 user + ASN sync from PeeringDB profile:
   - Added PeeringDB client abstraction for token/profile calls and profile normalization.
   - Upserts local `app_user` and replaces `user_asn` mappings based on authorized networks.
4. Implemented Phase 3 Step 3.4 session + logout behavior:
   - Added signed cookie session middleware configuration.
   - Added `/auth/logout` session clear + audit event.
   - Added placeholder guarded `/onboarding` and `/error` routes for auth redirects.
5. Implemented Phase 3 Step 3.5 integration-style auth tests (`tests/auth`):
   - Success callback path.
   - Invalid/missing state path.
   - Token exchange failure path.
   - Nonce mismatch path.
   - Callback replay protection path.
6. Added manual browser integration instructions for Phase 3 in `README.md` (required due no browser in this environment).
7. Expanded `.env.example` with auth/session runtime settings (`APP_ENV`, session cookie flags, OAuth TTL/scopes/timeout).

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest tests/auth -q` passed.
4. `uv run pytest -q` passed.

In progress
1. Phase 3 implementation complete.
2. Real browser-based OIDC checks still pending execution outside this environment (instructions documented in `README.md`).

Next
1. Execute the README browser checklist against a real PeeringDB OAuth app and record outcomes.
2. Start Phase 4 Step 4.1 request creation endpoint with ASN ownership checks.
3. Add API auth helpers for current session user to support Phase 4 route guards.

Known bugs / regressions
1. No automated regressions detected in current local test suite.
2. Nonce verification currently depends on `id_token` presence in token response; browser validation against live PeeringDB remains required.

Notes
1. Added test package `__init__.py` files to keep strict `mypy` module resolution stable with multiple `conftest.py` modules.

---

Update: 2026-02-10 (Phase 3 auth nonce fix + detailed callback error surface)

Decision
1. Enforced OIDC scope requirement by always including `openid` in configured PeeringDB scopes to ensure `id_token` nonce validation can succeed.
2. Expanded callback error redirect contract to include user-visible `detail` codes/messages for faster diagnosis without reading server logs.

Completed
1. Fixed likely `invalid_nonce` root cause path:
   - Updated scope normalization in `app/config.py` to inject `openid` when missing and deduplicate configured scopes.
   - Updated `.env.example` default `PEERINGDB_SCOPES` to `openid profile email networks`.
   - Updated `TECH_STACK.md` documented scope list to include `openid`.
2. Added richer callback error details:
   - Extended `/auth/callback` redirect helper to include `detail` query parameter.
   - Added nonce error detail-code mapping (for example `missing_id_token`, `missing_nonce_claim`, `nonce_mismatch`).
   - Added structured detail propagation for `oauth_error`, state errors, and upstream auth failures.
3. Expanded `/error` response payload:
   - Added user-facing `message` per error code.
   - Added passthrough `detail` field for callback diagnostics.
4. Updated tests:
   - Scope assertion now expects `openid profile email networks`.
   - Added coverage for nonce mismatch detail code.
   - Added coverage for missing `id_token` returning `invalid_nonce` with `missing_id_token` detail and message payload.
   - Added config tests for environment-scope normalization (`openid` injection and deduplication).
5. Updated README Phase 3 instructions to explicitly require `PEERINGDB_SCOPES` including `openid`.

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest -q` passed.

In progress
1. No active implementation tasks in this update.

Next
1. Re-run browser integration login against live PeeringDB with updated `PEERINGDB_SCOPES` and verify callback reaches `/onboarding`.
2. Capture any remaining live-provider callback detail codes from `/error` for follow-up hardening if needed.

Known bugs / regressions
1. No regressions detected in local automated checks for this scope.

---

Update: 2026-02-10 (PeeringDB OAuth registration algorithm lesson documented)

Decision
1. Captured a live-integration lesson that successful PeeringDB OIDC callback in this project also depends on OAuth app registration algorithm set to `RSA with SHA-2 256` (RS256).

Completed
1. Updated Phase 3 manual integration guidance in `README.md`:
   - Added explicit OAuth registration prerequisite to set algorithm `RSA with SHA-2 256` (RS256).
2. Updated `TECH_STACK.md` external API constraints:
   - Added PeeringDB registration algorithm requirement as an integration contract note.
3. Replaced `lessons.md` TODO stub with a concrete lesson entry:
   - Symptom, root cause, prevention rule, and good-vs-bad example for the nonce failure scenario.

In progress
1. No active implementation tasks.

Next
1. Keep this registration prerequisite in onboarding/checklist docs for any future environment setup.
2. If additional live-auth pitfalls appear, append them to `lessons.md` and Phase 3 README checklist.

Known bugs / regressions
1. None identified for this documentation-only update.

---

Update: 2026-02-10 (Auth Option A documentation alignment)

Decision
1. Added authentication planning/documentation for Auth Option A:
   - Local credentials table with canonical `app_user` model.
   - Server CLI account provisioning with admin and associated ASN/network options.
2. Clarified option naming to avoid ambiguity with existing route-server options:
   - `Auth Option A` / `Auth Option B`
   - `Route Server Option A` / `Route Server Option B`

Completed
1. Updated `PRD.md` (Version 0.3):
   - Added Auth Option A scope, user stories, acceptance criteria, security expectations, and DoD coverage.
2. Updated `APP_FLOW.md` (Version 0.3):
   - Added `/auth/local/login` flow and explicit server CLI local-account provisioning flow.
3. Updated `BACKEND_STRUCTURE.md` (Version 0.3):
   - Added canonical-user + local-credential data model (`local_credential`, `user_network_access`) and related auth/env/edge-case contracts.
4. Updated `IMPLEMENTATION_PLAN.md` (Version 0.4):
   - Added detailed Auth Option A implementation steps (schema, auth route, CLI provisioning, tests).
   - Disambiguated auth option naming from route-server options.
5. Updated `TECH_STACK.md` (Version 0.3):
   - Documented local credential handling approach and authentication mode support without adding new external dependencies.

In progress
1. No implementation code changes in this update.

Next
1. Resolve open question: for Auth Option A, should empty associated-network assignment be unrestricted or deny-by-default?
2. Start implementation from `IMPLEMENTATION_PLAN.md` Phase 3 Auth Option A steps:
   - schema migration
   - local credential service/route
   - CLI provisioning command
   - tests

Known bugs / regressions
1. None identified for this documentation-only update.

Notes
1. This update changes planning contracts only; runtime behavior is unchanged until implementation starts.

---

Update: 2026-02-10 (Auth Option A implementation completed)

Decision
1. Implemented associated-network authorization semantics as documented in planning:
   - If a user has one or more `user_network_access` rows, request target network must be in that set.
   - If a user has no `user_network_access` rows, network eligibility is unrestricted.

Completed
1. Implemented Phase 3 Auth Option A schema/model alignment:
   - Added ORM models and relationships for `local_credential` and `user_network_access`.
   - Made `app_user.peeringdb_user_id` nullable while preserving uniqueness when present.
   - Added Alembic revision `20260210_0002_auth_option_a_schema.py`.
2. Implemented local credential auth service and login route:
   - Added stdlib PBKDF2-HMAC password hash/verify helpers with constant-time comparison in `app/auth/local_credentials.py`.
   - Added `POST /auth/local/login` with deterministic invalid-credential behavior, disabled-credential handling, session establishment, and audit events.
3. Implemented server CLI local account provisioning:
   - Added `app/cli/users.py` with `create` command supporting:
     - username/password input mode (`--password` or `--password-stdin`)
     - optional admin flags (`--admin` / `--no-admin`)
     - repeatable ASN assignment (`--asn`)
     - repeatable associated-network assignment (`--zt-network-id`)
   - Added provisioning audit event `auth.local_account.provisioned`.
4. Implemented associated-network enforcement in request/onboarding paths:
   - Enforced network restriction checks in `POST /api/v1/requests`.
   - Filtered `/onboarding` network list by `user_network_access` when restrictions exist.
5. Added/updated tests:
   - Added `tests/auth_local` integration coverage for local login success/failure/disabled/toggle/no-ASN and onboarding network filtering.
   - Added `tests/cli` coverage for CLI provisioning success, unknown-network rollback, and password-policy validation.
   - Added workflow integration coverage for associated-network authorization enforcement.
   - Updated config and fixture coverage for new local-auth settings fields.
6. Updated `.env.example` with local-auth runtime settings:
   - `LOCAL_AUTH_ENABLED`
   - `LOCAL_AUTH_PASSWORD_MIN_LENGTH`
   - `LOCAL_AUTH_PBKDF2_ITERATIONS`

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest -q` passed.
4. `uv run env DATABASE_URL=sqlite:////tmp/zt_ix_auth_option_a.db alembic upgrade head && uv run env DATABASE_URL=sqlite:////tmp/zt_ix_auth_option_a.db alembic downgrade base && uv run env DATABASE_URL=sqlite:////tmp/zt_ix_auth_option_a.db alembic upgrade head` passed.

In progress
1. No active implementation tasks in this update.

Next
1. If desired, add operator/admin UI form surfaces for local login and local-account lifecycle actions.
2. If desired, add throttling/lockout controls for repeated local login failures (Phase 7 security hardening).

Known bugs / regressions
1. No regressions detected in local lint/type/tests for this scope.

---

Update: 2026-02-10 (Phase 5 split into self-contained sub-phases)

Decision
1. Phase 5 is now split into smaller documentation sub-phases while preserving original scope and step IDs (`5.1` through `5.14`).

Completed
1. Updated `IMPLEMENTATION_PLAN.md` to Version 0.5:
   - Added Sub-phase 5A: Provider Foundation and Membership Provisioning.
   - Added Sub-phase 5B: Route Server Desired Config Generation.
   - Added Sub-phase 5C: Route Server Apply and Convergence.
   - Added self-contained outcomes for each sub-phase.
   - Kept consolidated Phase 5 exit criteria and verification section.

In progress
1. No implementation code changes in this update.

Next
1. Execute Sub-phase 5A steps (`5.1` to `5.8`) as the next implementation block.
2. Keep route-server rendering (`5.9` to `5.11`) and apply/convergence (`5.12` to `5.14`) as separate follow-on blocks.

Known bugs / regressions
1. None identified for this documentation-only update.

---

Update: 2026-02-10 (Checklist + blocker tracking format applied to implementation plan)

Decision
1. `IMPLEMENTATION_PLAN.md` is now checklist-driven (`[x]` complete, `[ ]` open) with explicit blocker annotations.
2. Queue dispatch from admin approve/retry is explicitly deferred to Phase 5 while retaining the current placeholder hook.
3. JSON responses for workflow "page" routes are accepted for the current state; UI/template integration is tracked as open and blocked until Phase 6 execution.

Completed
1. Rewrote `IMPLEMENTATION_PLAN.md` to Version 0.6 with:
   - status checklists for all phases and verification items,
   - explicit gap tracking through and beyond Phase 4,
   - concrete blocker metadata (`Blocked by` + `Reason`) for queueing, frontend/UI integration, and route-server dependencies.
2. Updated `AGENTS.md` to enforce:
   - checklist-based implementation plan maintenance,
   - explicit blocker documentation,
   - required backfill of blocked gaps once dependencies are completed.

In progress
1. No implementation code changes in this update.

Next
1. Start Phase 5 Step 5.1 to Step 5.4:
   - provider interface,
   - `central` and `self_hosted_controller` adapters,
   - Celery provider resolution and real queue dispatch replacing the placeholder hook.
2. After Phase 5 stabilizes request/provisioning behavior, execute Phase 6 UI/template integration to replace JSON-only route responses for workflow pages.

Known bugs / regressions
1. No runtime regressions identified; this update is documentation-only.

---

Update: 2026-02-10 (Implementation plan marks auto-approval as configurable)

Decision
1. Auto-approval is now tracked in planning as a configurable approval mode while keeping manual admin approval as the default.

Completed
1. Updated `IMPLEMENTATION_PLAN.md` to Version 0.7:
   - Marked policy auto-approval as a configurable option in planning assumptions.
   - Added explicit Phase 4 checklist item (Step 4.7) for configurable approval-mode support.
   - Added blocker metadata tying auto-approval execution to real async dispatch wiring in Phase 5.
   - Added matching exit-criteria and verification checklist entries for approval-mode behavior and audit coverage.

In progress
1. No implementation code changes in this update.

Next
1. Implement Phase 5 Step 5.1 to Step 5.4 (provider wiring + real Celery dispatch), then execute Phase 4 Step 4.7 for configurable approval-mode behavior.
2. Finalize product/security guardrails for auto-approval eligibility and fallback behavior before implementation.

Known bugs / regressions
1. None identified for this documentation-only update.

---

Update: 2026-02-10 (Sub-phase 5A implemented in code)

Completed
1. Implemented Phase 5 Sub-phase 5A Step 5.1 provider contract foundation:
   - Added provider-agnostic `ProvisionResult` model and provisioning provider protocol.
   - Added normalized provider error taxonomy for auth/network/request failures.
2. Implemented Step 5.2 and Step 5.3 provider adapters:
   - Added ZeroTier Central adapter with token auth (`Authorization: token <token>`).
   - Added self-hosted controller adapter with `X-ZT1-Auth` auth header.
   - Added response normalization for member ID, authorization state, and assigned IPs.
3. Implemented Step 5.4 Celery dispatch and provider-selection wiring:
   - Added Celery task module and real queue dispatch from admin approve/retry paths.
   - Added provider factory selection by `ZT_PROVIDER` with deterministic misconfiguration errors.
4. Implemented Step 5.5 and Step 5.7 provisioning state machine and retry-safe behavior:
   - Added provisioning service to transition `approved -> provisioning -> active|failed`.
   - Added idempotent membership upsert behavior and deterministic failure persistence (`last_error`, retry increment).
   - Added audit events for provisioning start/success/failure/skip branches.
5. Implemented Step 5.6 request API membership visibility coverage:
   - Confirmed request serialization includes membership payload when present.
   - Added integration test coverage for membership inclusion in request detail API responses.
6. Implemented Step 5.8 test coverage:
   - Added provider contract tests for both adapters.
   - Added provider factory selection and credential-validation tests.
   - Added provisioning service tests for success, failure, skip, and idempotent upsert behavior.
   - Added Celery task/dispatch behavior tests and provider-resolution path coverage.
7. Updated implementation tracking docs:
   - Updated `IMPLEMENTATION_PLAN.md` to Version 0.8 with Sub-phase 5A checklist completion and blocker/status updates.

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest tests/provisioning tests/workflow -q` passed.
4. `uv run pytest -q` passed.

In progress
1. No active implementation tasks in this update.

Next
1. Implement Phase 5 Sub-phase 5B (Step 5.9 to Step 5.11): route-server sync service, deterministic BIRD peer rendering, and ROA/RPKI policy enforcement.
2. Implement Phase 4 Step 4.7 configurable approval mode once policy guardrails are finalized.

Known bugs / regressions
1. No regressions detected in local lint/type/tests after Sub-phase 5A changes.

---

Update: 2026-02-10 (Sub-phase 5B implemented in code)

Completed
1. Implemented Phase 5 Sub-phase 5B Step 5.9 route-server SSH fanout service:
   - Added `app/provisioning/route_servers.py` for config-driven remote route-server sync.
   - Added runtime settings/env parsing for route-server host inventory, SSH options, remote config dir, and local route-server ASN.
2. Implemented Step 5.10 deterministic per-ASN BIRD snippet rendering:
   - Added deterministic renderer based on request ID, ASN, node ID, and ZeroTier-assigned endpoint IPs.
   - Added one explicit BGP peer stanza per assigned endpoint address.
3. Implemented Step 5.11 ROA/RPKI policy enforcement in generated config path:
   - Added generated BIRD import filters using `roa_check(ztix_roa_v4, ...)` and `roa_check(ztix_roa_v6, ...)`.
4. Integrated route-server sync into provisioning workflow:
   - Route-server sync now runs after successful member authorization in provisioning path.
   - Sync results are audited; sync failures transition request to `failed` with actionable error code/message.
5. Added automated tests for route-server sub-phase behavior:
   - New `tests/route_servers/test_sync.py` covers rendering output, SSH fanout, and aggregated failure handling.
   - Extended provisioning service tests to cover route-server sync success and failure branches.
6. Updated docs and tracking:
   - Updated `.env.example` with route-server settings.
   - Added README route-server setup section (per-router package install, SSH prep, BIRD include, RPKI cron example, syntax check).
   - Aligned product/system docs with route-server Option A scope:
     - `PRD.md`
     - `APP_FLOW.md`
     - `TECH_STACK.md`
     - `BACKEND_STRUCTURE.md`
   - Updated `IMPLEMENTATION_PLAN.md` to Version 0.9 with Step 5.9 to Step 5.11 marked complete.

Verification
1. `uv run ruff check .` passed.
2. `uv run mypy .` passed.
3. `uv run pytest tests/provisioning -q` passed.
4. `uv run pytest tests/route_servers -q` passed.
5. Generated-config syntax check passed with `bird -p -c /tmp/ztix-bird.conf`.

In progress
1. No active implementation tasks in this update.

Next
1. Implement Phase 5 Sub-phase 5C (Step 5.12 to Step 5.14): safe BIRD apply/check workflow per route server and convergence gating for request status transitions.
2. Keep configurable approval mode (Phase 4 Step 4.7) blocked pending product/security guardrail sign-off.

Known bugs / regressions
1. None identified in local lint/type/tests for Sub-phase 5B scope.
